{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical impacts of the Dawesville Cut on some aspects of water quality in the Peel-Harvey estuary: as inferred from remote sensing data using modern techniques.\n",
    "\n",
    "## Final Project for ENVT4408, Semester 2, 2024.\n",
    "\n",
    "### Ross Marriott, Student No. 19324501\n",
    "#### School of Agriculture and Environment, The University of Western Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date:** 28 October, 2024\n",
    "    \n",
    "Version 1 written in Python 3 using ESRI ArcPro v3.2.2 Notebooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "#### The Peel-Harvey system and the Dawesville Cut\n",
    "The Peel-Harvey estuary system is comprised of the Harvey estuary and the Peel inlet, located at the southern margin of the sprawling metropolitan area of the capital city of Perth, Western Australia. Algal blooms within this system have been problematic historically, particularly during summer months of the 1980s and early 1990s. The algal blooms had resulted in noxious gas production and decaying algal wracks along various shoreline locations, which had bothered neighbouring residential communities. \n",
    "\n",
    "The Dawesville Cut (also known as the Dawesville Channel) is a man-made channel that was constructed 1990 - April 1994 for the purpose of alleviating these problems by increasing the mixing of higher salinity coastal waters with the estuary and inlet. However, algal blooms continue to be problematic in some parts of the system.\n",
    "\n",
    "#### Concurrent advancements in Remote Sensing methods\n",
    "In the intervening period since the Dawesville Cut was constructed, there have been many advances in the field of Remote Sensing. Multi- and hyper-spectral sensors mounted on various remote sensing platforms, including satellites, planes, vessels, and drones have been used to capture and characterise the spectral signatures of a range of phenomena over space and time. The Landsat series of satellites, which commenced in 1972, is the longest-running of these programs. Much of these data are now freely available, and recent advances in geographic information system software and methods has led to some researchers revisiting the analysis of past events. For instance, Ho *et al*, (2017) recently used multispectral data captured by the Landsat 5 Thematic Mapper (TM) sensor during 1984-2011 to analyse historical phytoplankton blooms in Lake Erie in the United States. Bugnot *et al*, (2018) used ratios of reflectance data from different visible light spectra (blue, green, red) recorded by Landsat sensors to model historical environmental changes in Australian estuaries.\n",
    "\n",
    "Accordingly, it is possible that historical changes in ratios of visible light reflectance for the Peel-Harvey estuary, before and after the Dawesville Cut was constructed, could reflect impacts of this intervention for improving water quality within this system.\n",
    "\n",
    "References cited:\n",
    "\n",
    "Bugnot, A.B., Lyons, M.B., Scanes, P., Clark, G.F., Fyfe, S.K., Lewis, E.L., & Johnson, E.L. (2018). A novel framework for the use of remote sensing for monitoring catchments at continental scales. *Journal of Environmental Management* **217**: 939-950. https://doi.org/10.1016/j.jenvman.2018.03.058\n",
    "\n",
    "Ho, J.C., Stumpf, R.P., Bridgeman, T.B, & Michalak, A.M. (2017). Using Landsat to extend the historical record of lacustrine phytoplankton blooms: A Lake Erie case study. *Remote Sensing of Environment* **191**: 273-285. http://dx.doi.org/10.1016/j.rse.2016.12.013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim\n",
    "To evaluate the likely impacts of the Dawesville Cut on water quality in the Peel-Harvey system by comparing and contrasting spatial patterns in the ratios of visible light spectra reflectance, before and after the Cut was constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "**1.** Identify indices to measure historical changes in water quality within the estuary and inlet over time (likely turbidity and density of phytoplankton / organic particulates).\n",
    "\n",
    "**2.** Explore seasonal changes in each index within the estuary and inlet.\n",
    "\n",
    "**3.** Has there been a change which may possibly attributed to the Cut? Compare the water quality indices measured on satellite images taken two years before (i.e., 1988) and after (i.e., 1996) construction of the Dawesville Cut.\n",
    "\n",
    "**4.** If there has been a change, assess spatially where these changes occurred and interpret findings (refer to StoryMap presentation for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, arcpy, math\n",
    "from arcpy import env\n",
    "from arcpy.sa import *\n",
    "from arcgis.gis import GIS\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confirm license**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(\"pro\")\n",
    "arcpy.CheckOutExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define path variables, load shape file**\n",
    "\n",
    "Set path to inFolder based on the location of all subfolders containing downloaded raster images (from EO Browser, https://www.sentinel-hub.com/explore/eobrowser/) and outputs from running this script. Save all required imagery (separate high resolution TIFF files for Landsat 5 Bands 1-4 to a subfolder called \"Input_rasters\").\n",
    "\n",
    "AOI = Shape file created beforehand in ArcGIS Pro by manually digitising around the shoreline of the Peel-Harvey estuary. This shape file will be used to mask out the surrounding land. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFolder = r\"C:\\Users\\Owner\\Documents\\ENVT4408\\Project\\Data\"\n",
    "inFolder1 = inFolder + \"\\\\Input_rasters\" # Rasters from Landsat 5 Bands 1-4.\n",
    "AOI = inFolder + \"\\\\\" + \"AOI.shp\"\n",
    "# Checks:\n",
    "print(AOI)\n",
    "print(inFolder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and rename input rasters and apply a suitable projection**\n",
    "\n",
    "All were downloaded with WGS 1984 GCS and require projection to GDA2020 Zone 50 (EPSG7850) to ensure distances are in meters, with direction preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Projected Coordinate System)\">name (Projected Coordinate System)</td><td title=\"GDA2020_MGA_Zone_50\">GDA2020_MGA_Zone_50</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"7850\">7850</td></tr><tr><td id = \"td0\" title=\"linearUnitName (Linear Unit)\">linearUnitName (Linear Unit)</td><td title=\"Meter\">Meter</td></tr></table><div class=\"subtitle\">spatialReference.GCS</div><style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GDA2020\">GDA2020</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"7844\">7844</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"GDA2020\">GDA2020</td></tr></table>"
      ],
      "text/plain": [
       "<geoprocessing spatial reference object object at 0x00000292AFC0C1B0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.Describe(AOI).spatialReference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AOI is already in this PCS so we do not need to reproject this shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loops through all input rasters to firstly rename copies of them, and then to reproject those copies into the required PCS, ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output geodatabase to store results (if one has not before)\n",
    "outFolder = inFolder\n",
    "pcs_db = os.path.join(outFolder, \"pcsout.gdb\")\n",
    "if arcpy.Exists(pcs_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"pcsout.gdb\")\n",
    "    \n",
    "# Set the PCS we want to reproject to\n",
    "out_coordinate_system = arcpy.SpatialReference('GDA2020_MGA_Zone_50')\n",
    "\n",
    "# Run the for-loop to reproject copies of input rasters and save to geodatabase\n",
    "# Rename outputs to concise but informative names (e.g., \"Mar_1988_Blue_pcs\")\n",
    "arcpy.env.overwriteOutput = True\n",
    "for file in os.listdir(inFolder1):\n",
    "    path = inFolder1 + \"\\\\\" + file\n",
    "    Month = file[5:7]\n",
    "    if Month == \"03\":\n",
    "        Month = \"Mar\"\n",
    "    elif Month == \"07\":\n",
    "        Month = \"Jul\"\n",
    "    elif Month == \"09\":\n",
    "        Month = \"Sep\"\n",
    "    else:\n",
    "        Month = \"Dec\"\n",
    "    Year = file[0:4]\n",
    "    Type = file[-12]\n",
    "    if Type == \"1\":\n",
    "        Type = \"Blue\"\n",
    "    elif Type == \"2\":\n",
    "        Type = \"Green\"\n",
    "    elif Type == \"3\":\n",
    "        Type = \"Red\"\n",
    "    else:\n",
    "        Type = \"NIR\" # Near infra-red band images were also saved but not used.\n",
    "    newfile_nam = Month + \"_\" + Year + \"_\" + Type\n",
    "    newfile = pcs_db + \"\\\\\" + newfile_nam\n",
    "    # Note: do not need to use raster file extension if saving to a gdb\n",
    "    arcpy.management.ProjectRaster(path, newfile, out_coordinate_system, \"BILINEAR\")\n",
    "    print(newfile_nam + \" saved to pcsout.gdb\")\n",
    "    \n",
    "# Reset default behaviour incase we inadvertently overwrite     \n",
    "arcpy.env.overwriteOutput = False \n",
    "    \n",
    "print(\"Finished copying renamed, reprojected rasters\")\n",
    "\n",
    "# Check the projection has worked for the last raster in the loop\n",
    "print(newfile)\n",
    "arcpy.Describe(newfile).spatialReference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To constrain our analyses to only the water bodies, we clip each raster to the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output geodatabase to store results\n",
    "clp_db = os.path.join(outFolder, \"clippedout.gdb\")\n",
    "if arcpy.Exists(clp_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"clippedout.gdb\")\n",
    "\n",
    "# Run the for loop to clip the rasters to AOI and save in clippedout.gdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = pcs_db\n",
    "for file in arcpy.ListDatasets():\n",
    "    in_raster = pcs_db + \"\\\\\" + file\n",
    "    out_raster = clp_db + \"\\\\\" + file + \"_clp\"\n",
    "    arcpy.Clip_management(in_raster, \"#\", out_raster, AOI, \"#\", \"ClippingGeometry\", \"MAINTAIN_EXTENT\")\n",
    "    print(file + \"_clp saved to \" + clp_db) \n",
    "    \n",
    "# Reset default behaviour incase we inadvertently overwrite     \n",
    "arcpy.env.overwriteOutput = False \n",
    "    \n",
    "print(\"Finished clipping the rasters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File management: Store the clipped rasters in separate geodatabases for computations, grouped by Month and Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = clp_db\n",
    "\n",
    "# Define lists for referencing within loop\n",
    "yearVals = ['1988','1996'] # Pre- and Post-construction of the Cut.\n",
    "monthVals = ['Mar','Jul','Sep','Dec']\n",
    "# Use nested loop to create a \"timeVals\" list combining the above 2\n",
    "# lists in the format of Month_Year, comprising all of the time points\n",
    "# that we will be analysing:\n",
    "timeVals = list()\n",
    "for i in list(range(0,len(yearVals))):\n",
    "    for j in list(range(0,len(monthVals))):\n",
    "        timeVals.append(monthVals[j] + \"_\" + yearVals[i])\n",
    "print(timeVals)\n",
    "\n",
    "# Make geodatabases to group clipped rasters within\n",
    "for t in timeVals:\n",
    "    t = t + \".gdb\"\n",
    "    if arcpy.Exists(os.path.join(outFolder, t)):\n",
    "        pass\n",
    "    else:\n",
    "        arcpy.CreateFileGDB_management(outFolder, t)\n",
    "\n",
    "# Allocate each raster to its respective geodatabase        \n",
    "for file in arcpy.ListDatasets():\n",
    "    path = clp_db + \"\\\\\" + file\n",
    "    Year = file[4:8]\n",
    "    Month = file[0:3]\n",
    "    t_group = Month + \"_\" + Year + \".gdb\"\n",
    "    new_db = os.path.join(outFolder, t_group)\n",
    "    newfile = new_db + \"\\\\\" + file\n",
    "    arcpy.management.CopyRaster(path, newfile, pixel_type=\"64_BIT\")\n",
    "    \n",
    "arcpy.env.overwriteOutput = False \n",
    "print(\"Finished sorting files\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spatial analyses**\n",
    "\n",
    "Calculate the spectral index rasters and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output geodatabases to store results\n",
    "g_on_r_db = os.path.join(outFolder, \"g_on_rout.gdb\")\n",
    "if arcpy.Exists(g_on_r_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"g_on_rout.gdb\")\n",
    "\n",
    "b_on_r_db = os.path.join(outFolder, \"b_on_rout.gdb\")\n",
    "if arcpy.Exists(b_on_r_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"b_on_rout.gdb\")\n",
    "print(\"Spectral index geodatabases created\")\n",
    "\n",
    "# Create list of geodatabases for previous groupings of rasters by Month and Year\n",
    "group_dbs = list()\n",
    "for i in list(range(0,len(timeVals))):\n",
    "    group_dbs.append(timeVals[i] + \".gdb\")\n",
    "print(group_dbs)\n",
    "\n",
    "# Run the for loop to calculate the 2 indices for each group, then save\n",
    "arcpy.env.overwriteOutput = True\n",
    "for g in list(range(0,len(group_dbs))):\n",
    "    gdb_file = group_dbs[g]\n",
    "    Month_Year = gdb_file[0:8]\n",
    "    print(\"Processing rasters for \" + Month_Year + \" group\")\n",
    "    gdb_path = os.path.join(outFolder, gdb_file)\n",
    "    arcpy.env.workspace = gdb_path\n",
    "    in_rasters = arcpy.ListDatasets()\n",
    "    for file in in_rasters:\n",
    "        Type = file[9:-4]\n",
    "        if Type == \"Red\":\n",
    "            red_rast = file\n",
    "        elif Type == \"Blue\":\n",
    "            blu_rast = file\n",
    "        elif Type == \"Green\":\n",
    "            gre_rast = file\n",
    "        else:\n",
    "            nir_rast = file # not used.           \n",
    "    # 1. Calculate Green on Red index\n",
    "    g_on_r = g_on_r_db + \"\\\\\" + Month_Year + \"_g_on_r\"\n",
    "    g_on_r_rast = Divide(gre_rast, red_rast)\n",
    "    arcpy.management.CopyRaster(g_on_r_rast, g_on_r, pixel_type=\"64_BIT\")\n",
    "    print(\"Green on Red calculated\")    \n",
    "    # 2. Calculate Blue on Red index\n",
    "    b_on_r = b_on_r_db + \"\\\\\" + Month_Year + \"_b_on_r\"\n",
    "    b_on_r_rast = Divide(blu_rast, red_rast)\n",
    "    arcpy.management.CopyRaster(b_on_r_rast, b_on_r, pixel_type=\"64_BIT\")\n",
    "    print(\"Blue on Red calculated\")\n",
    "\n",
    "arcpy.env.overwriteOutput = False \n",
    "    \n",
    "print(\"Finished calculating spectral indices\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Green on Red and Blue on Red indices across time using Image Regression.\n",
    "\n",
    "We will compare values at a random sample of 100 points within the estuary, defined by the AOI, at each successive time point with the earliest (March 1988). The random samples will be taken a minimum distance of 500m apart, to reduce prospect for spatial autocorrelation affecting results and ensure that the points have good representation across the estuary. The resulting output, for each index, will be a table of values for every sampled point, for each time point (columns). Out of convenience, we then convert this table into an Excel file and export it so that we may analyse it in a different software (R). (Note: this could also be done here using Python, but I have chosen R to do this because of my greater familiarity with statistical functions in that software). A correlation matrix will be constructed to compare the strength of pairwise linear associations between index values obtained across the same locations between different times (**(i)** between different months in the same year to assess seasonal differences; and **(ii)** between different years for the same month to assess changes before and after construction of the Cut). For each month, a linear regression will also be fitted to compare values at the sampled points between the 1988 raster (X axis) and 1996 raster (Y axis), and the slope and intercept estimates, with their 95% confidence intervals, will be saved, for plotting. Image Regression is useful to complement the correlation analyses because we can make more specific inferences about comparison of the spatial distribution of index values over time. For instance, an estimate of slope not significantly different from 1 and intercept not significantly different from 0 would suggest that the spatial distribution of values has not changed over time (contingent upon the statistical assumptions of this simple model being met). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Since the random seed has not been set, running the following cell will result in a different random sample of points, and therefore different estimates from the resulting correlation and regression analyses. The assumption is that a different random sample would not substantively change the results, considering that all such random samples would suitably represent the spatial distribution of index values in the estuary and inlet captured at each time point. One extension of this study would be to investigate the sensitivity to results of this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random sample of 100 points.\n",
    "\n",
    "# NOTE: If you re-run and overwrite randompts.shp you're likely to get different \n",
    "#       results, generated from a new set of randomly allocated points. That is why\n",
    "#       arcpy.env.overwriteOutput is not set to True for this cell.\n",
    "\n",
    "arcpy.management.CreateRandomPoints(outFolder, \"randompts\", AOI, \n",
    "                                    number_of_points_or_field = 100, \n",
    "                                    minimum_allowed_distance = 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample points from each raster, separately for each index, and save to table.\n",
    "\n",
    "randompts = outFolder + \"\\\\\" + \"randompts.shp\"\n",
    "\n",
    "# Specify variables for output feature classes\n",
    "sample_g_on_r = g_on_r_db + \"\\\\\" + \"sample_g_on_r\"\n",
    "sample_b_on_r = b_on_r_db + \"\\\\\" + \"sample_b_on_r\"\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Green on Red index\n",
    "arcpy.env.workspace = g_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "Sample(raster_list, randompts, sample_g_on_r)\n",
    "\n",
    "print(\"Finished sampling values from Green on Red rasters\")  \n",
    "\n",
    "# Blue on Red index\n",
    "arcpy.env.workspace = b_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "Sample(raster_list, randompts, sample_b_on_r) \n",
    "\n",
    "arcpy.env.overwriteOutput = False\n",
    "\n",
    "print(\"Finished sampling values from Blue on Red rasters\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert output to an Excel table and export.\n",
    "\n",
    "# Create an output folder location to store results\n",
    "regress_dir = os.path.join(outFolder, \"image_regress_out\")\n",
    "if os.path.exists(regress_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(regress_dir)\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "g_on_r_out_xls = regress_dir + \"\\\\\" + \"g_on_r_100_randpts.xls\"\n",
    "b_on_r_out_xls = regress_dir + \"\\\\\" + \"b_on_r_100_randpts.xls\"\n",
    "\n",
    "arcpy.conversion.TableToExcel(sample_g_on_r, g_on_r_out_xls)\n",
    "arcpy.conversion.TableToExcel(sample_b_on_r, b_on_r_out_xls)\n",
    "\n",
    "arcpy.env.overwriteOutput = False\n",
    "\n",
    "print(\"Excel files with raster values ready and saved in \" + regress_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have done the image regressions, which analyse whether the distribution of values has changed, it would also be good to look at how the average values have changed. We can do this in a convenient way by extracting from the metadata for each raster the mean and standard deviation of the pixel values (using the \"GetRasterProperties\" function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of g_on_r and b_on_r rasters, and save.\n",
    "\n",
    "# Create an output folder location to store results\n",
    "means_dir = os.path.join(outFolder, \"mean_stdev_indices_out\")\n",
    "if os.path.exists(means_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(means_dir)\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Green on Red index\n",
    "g_on_r_names = list()\n",
    "g_on_r_means = list()\n",
    "g_on_r_stdevs = list()\n",
    "arcpy.env.workspace = g_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = g_on_r_db + \"\\\\\" + in_raster\n",
    "    meanval = arcpy.management.GetRasterProperties(file, \"MEAN\")\n",
    "    stdevval = arcpy.management.GetRasterProperties(file, property_type = \"STD\")\n",
    "    g_on_r_names.append(in_raster[0:8])\n",
    "    g_on_r_means.append(meanval)\n",
    "    g_on_r_stdevs.append(stdevval)\n",
    "    \n",
    "g_on_r_stats = pd.DataFrame({'Month_Year': g_on_r_names,\n",
    "                            'Mean': g_on_r_means, 'StDev': g_on_r_stdevs})\n",
    "g_on_r_statsout = means_dir + \"\\\\\" + \"mean_stdev_g_on_r.xlsx\"\n",
    "g_on_r_stats.to_excel(g_on_r_statsout)\n",
    "print(\"Green on Red index statistics computed for each raster:\\n\")\n",
    "print(g_on_r_stats)\n",
    "\n",
    "## Blue on Red index\n",
    "b_on_r_names = list()\n",
    "b_on_r_means = list()\n",
    "b_on_r_stdevs = list()\n",
    "arcpy.env.workspace = b_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = b_on_r_db + \"\\\\\" + in_raster\n",
    "    meanval = arcpy.management.GetRasterProperties(file, \"MEAN\")\n",
    "    stdevval = arcpy.management.GetRasterProperties(file, \"STD\")\n",
    "    b_on_r_names.append(in_raster[0:8])\n",
    "    b_on_r_means.append(meanval)\n",
    "    b_on_r_stdevs.append(stdevval)\n",
    "    \n",
    "b_on_r_stats = pd.DataFrame({'Month_Year': b_on_r_names,\n",
    "                            'Mean': b_on_r_means, 'StDev': b_on_r_stdevs})\n",
    "b_on_r_statsout = means_dir + \"\\\\\" + \"mean_stdev_b_on_r.xlsx\"\n",
    "b_on_r_stats.to_excel(b_on_r_statsout)\n",
    "print(\"\\nBlue on Red index statistics computed for each raster:\\n\")\n",
    "print(b_on_r_stats)\n",
    "\n",
    "arcpy.env.overwriteOutput = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using map algebra we subtract the 1988 from the 1996 raster for each month and spectral index to obtain rasters showing the net change over that time period in the index value on a map, for each respective month.\n",
    "\n",
    "Note: for convenience, I have used a Python dictionary structure to temporarily store together rasters of the same year and then refer to them on lines 38 and 39 using the corresponding Month key, to ensure that I am peforming the subtraction on rasters for the same month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each index and month, calculate the difference rasters and store them.\n",
    "\n",
    "# Create an output geodatabases to store results\n",
    "g_on_rdiff_db = os.path.join(outFolder, \"g_on_rdiffout.gdb\")\n",
    "if arcpy.Exists(g_on_rdiff_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"g_on_rdiffout.gdb\")\n",
    "\n",
    "b_on_rdiff_db = os.path.join(outFolder, \"b_on_rdiffout.gdb\")\n",
    "if arcpy.Exists(b_on_rdiff_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"b_on_rdiffout.gdb\")\n",
    "    \n",
    "arcpy.env.overwriteOutput = True    \n",
    "\n",
    "# Green on Red index\n",
    "g_on_r_1988 = {} # create empty dictionaries\n",
    "g_on_r_1996 = {}\n",
    "arcpy.env.workspace = g_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = g_on_r_db + \"\\\\\" + in_raster\n",
    "    Month = in_raster[0:3]\n",
    "    Year = in_raster[4:8]\n",
    "    # Store each raster for that year with its\n",
    "    # corresponding 'Month' key in dictionary:\n",
    "    if Year == \"1988\":\n",
    "        g_on_r_1988[Month] = file\n",
    "    else:\n",
    "        g_on_r_1996[Month] = file\n",
    "# Calculate the difference rasters\n",
    "for i in list(range(0,len(monthVals))):\n",
    "    Month = monthVals[i]\n",
    "    # We use dictionary key to extract rasters \n",
    "    # for the same Month in different years:\n",
    "    Month_88 = g_on_r_1988[Month]\n",
    "    Month_96 = g_on_r_1996[Month]\n",
    "    # Calculate the difference between years\n",
    "    # controlling for time of year (same Month):\n",
    "    Month_diff = Minus(Month_96, Month_88)\n",
    "    # Save outputs to name-specific geodatabase:\n",
    "    Month_diffout = g_on_rdiff_db + \"\\\\\" + \"g_on_rdiff_\" + Month\n",
    "    arcpy.management.CopyRaster(Month_diff, Month_diffout, pixel_type=\"64_BIT\")\n",
    "    print(\"g_on_rdiff_\" + Month + \" raster calculated and saved to \" + g_on_rdiff_db)\n",
    "\n",
    "# Blue on Red index\n",
    "b_on_r_1988 = {} # create empty dictionaries\n",
    "b_on_r_1996 = {}\n",
    "arcpy.env.workspace = b_on_r_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = b_on_r_db + \"\\\\\" + in_raster\n",
    "    Month = in_raster[0:3]\n",
    "    Year = in_raster[4:8]\n",
    "    # Store each raster for that year with its\n",
    "    # corresponding 'Month' key in dictionary:\n",
    "    if Year == \"1988\":\n",
    "        b_on_r_1988[Month] = file\n",
    "    else:\n",
    "        b_on_r_1996[Month] = file\n",
    "# Calculate the difference rasters\n",
    "for i in list(range(0,len(monthVals))):\n",
    "    Month = monthVals[i]\n",
    "    # We use dictionary key to extract rasters \n",
    "    # for the same Month in different years: \n",
    "    Month_88 = b_on_r_1988[Month]\n",
    "    Month_96 = b_on_r_1996[Month]\n",
    "    # Calculate the difference between years\n",
    "    # controlling for time of year (same Month):\n",
    "    Month_diff = Minus(Month_96, Month_88)\n",
    "    # Save outputs to name-specific geodatabase:\n",
    "    Month_diffout = b_on_rdiff_db + \"\\\\\" + \"b_on_rdiff_\" + Month\n",
    "    arcpy.management.CopyRaster(Month_diff, Month_diffout, pixel_type=\"64_BIT\")\n",
    "    print(\"b_on_rdiff_\" + Month + \" raster calculated and saved to \" + b_on_rdiff_db)\n",
    "\n",
    "arcpy.env.overwriteOutput = False\n",
    "\n",
    "print(\"Finished calculating difference rasters. Make sure to check histogram distributions \\nprior to next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we address the question, where are the differences in index value, for each month? We use hotspot method to show on the change maps where the increases and decreases have occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotspot map for g_on_rdiff_Mar created and saved\n",
      "Hotspot map for g_on_rdiff_Jul created and saved\n",
      "Hotspot map for g_on_rdiff_Sep created and saved\n",
      "Hotspot map for g_on_rdiff_Dec created and saved\n",
      "Hotspot map for b_on_rdiff_Mar created and saved\n",
      "Hotspot map for b_on_rdiff_Jul created and saved\n",
      "Hotspot map for b_on_rdiff_Sep created and saved\n",
      "Hotspot map for b_on_rdiff_Dec created and saved\n",
      "Finished calculating hotspot vector files from the difference rasters\n"
     ]
    }
   ],
   "source": [
    "# Run hotspot analysis on the difference rasters, for each index and month.\n",
    "\n",
    "# Create an output geodatabases to store results\n",
    "g_on_rhotsp_db = os.path.join(outFolder, \"g_on_rhotspout.gdb\")\n",
    "if arcpy.Exists(g_on_rhotsp_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"g_on_rhotspout.gdb\")\n",
    "\n",
    "b_on_rhotsp_db = os.path.join(outFolder, \"b_on_rhotspout.gdb\")\n",
    "if arcpy.Exists(b_on_rhotsp_db):\n",
    "    pass\n",
    "else:\n",
    "    arcpy.CreateFileGDB_management(outFolder, \"b_on_rhotspout.gdb\")\n",
    "    \n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Green on Red index\n",
    "arcpy.env.workspace = g_on_rdiff_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = g_on_rdiff_db + \"\\\\\" + in_raster\n",
    "    Month = in_raster[-3:]\n",
    "    # Create points from the raster\n",
    "    g_on_r_pts = g_on_rhotsp_db + \"\\\\\" + \"g_on_r_\" + Month + \"_pts\"\n",
    "    arcpy.RasterToPoint_conversion(file, g_on_r_pts, raster_field=\"Value\")\n",
    "    # Create hotspot from points\n",
    "    g_on_r_hotsp = g_on_rhotsp_db + \"\\\\\" + \"g_on_r_\" + Month + \"_hotsp\"\n",
    "    arcpy.HotSpots_stats(g_on_r_pts, \"grid_code\", g_on_r_hotsp,\n",
    "                         Conceptualization_of_Spatial_Relationships=\"FIXED_DISTANCE_BAND\",\n",
    "                         Distance_Method=\"EUCLIDEAN_DISTANCE\", Standardization=\"NONE\",\n",
    "                         Distance_Band_or_Threshold_Distance=\"\", Self_Potential_Field=\"\",\n",
    "                         Weights_Matrix_File=\"\",\n",
    "                         Apply_False_Discovery_Rate__FDR__Correction=\"NO_FDR\")\n",
    "    print(\"Hotspot map for \" + in_raster + \" created and saved\")\n",
    "\n",
    "# Blue on Red index\n",
    "arcpy.env.workspace = b_on_rdiff_db\n",
    "raster_list = arcpy.ListDatasets()\n",
    "for in_raster in raster_list:\n",
    "    file = b_on_rdiff_db + \"\\\\\" + in_raster\n",
    "    Month = in_raster[-3:]\n",
    "    # Create points from the raster\n",
    "    b_on_r_pts = b_on_rhotsp_db + \"\\\\\" + \"b_on_r_\" + Month + \"_pts\"\n",
    "    arcpy.RasterToPoint_conversion(file, b_on_r_pts, raster_field=\"Value\")\n",
    "    # Create hotspot from points\n",
    "    b_on_r_hotsp = b_on_rhotsp_db + \"\\\\\" + \"b_on_r_\" + Month + \"_hotsp\"\n",
    "    arcpy.HotSpots_stats(b_on_r_pts, \"grid_code\", b_on_r_hotsp,\n",
    "                         Conceptualization_of_Spatial_Relationships=\"FIXED_DISTANCE_BAND\",\n",
    "                         Distance_Method=\"EUCLIDEAN_DISTANCE\", Standardization=\"NONE\",\n",
    "                         Distance_Band_or_Threshold_Distance=\"\", Self_Potential_Field=\"\",\n",
    "                         Weights_Matrix_File=\"\",\n",
    "                         Apply_False_Discovery_Rate__FDR__Correction=\"NO_FDR\")\n",
    "    print(\"Hotspot map for \" + in_raster + \" created and saved\")\n",
    "\n",
    "arcpy.env.overwriteOutput = False\n",
    "\n",
    "print(\"Finished calculating hotspot vector files from the difference rasters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
